import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import random
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# List of common user agents for rotation
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59'
]

def parse_og_metadata(url, retry_count=3):
    for attempt in range(retry_count):
        try:
            headers = {
                'User-Agent': random.choice(USER_AGENTS),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'max-age=0'
            }
            
            response = requests.get(
                url, 
                headers=headers, 
                timeout=15,
                verify=False,
                allow_redirects=True
            )
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            og_data = {
                'title': None,
                'description': None,
                'image': None,
                'site_name': None,
                'url': url
            }
            
            og_tags = soup.find_all('meta', property=lambda x: x and x.startswith('og:'))
            
            for tag in og_tags:
                property_name = tag.get('property', '').replace('og:', '')
                content = tag.get('content')
                
                if property_name in og_data:
                    og_data[property_name] = content
                    
            if og_data['image'] and not og_data['image'].startswith(('http://', 'https://')):
                og_data['image'] = urljoin(url, og_data['image'])
            
            if not og_data['title']:
                og_data['title'] = soup.title.string if soup.title else None
                
            if not og_data['description']:
                meta_desc = soup.find('meta', {'name': 'description'})
                og_data['description'] = meta_desc['content'] if meta_desc else None
                
            return og_data
            
        except requests.Timeout:
            st.warning(f"ì‹œë„ {attempt + 1}ê°€ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„ì¤‘...")
            time.sleep(2)
            
        except requests.RequestException as e:
            st.warning(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
            if attempt < retry_count - 1:
                time.sleep(2)
                continue
            else:
                st.error("ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None
                
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            return None

st.set_page_config(
    page_title="OG ë©”íƒ€ë°ì´í„° íŒŒì„œ",
    page_icon="ğŸ”",
    layout="wide"
)

st.markdown("""
    <style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .output-container {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 20px 0;
    }
    .example-sites {
        background-color: #e1e5eb;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

st.title('ğŸ” URL ë©”íƒ€ë°ì´í„° íŒŒì„œ')

# Example sites section
st.subheader('ì‚¬ì´íŠ¸ URL íŒŒì‹± ì˜ˆì‹œ ì‚¬ì´íŠ¸')
st.markdown("""
<div class="example-sites">
<b>ë‰´ìŠ¤ ì‚¬ì´íŠ¸:</b>
- https://www.chosun.com
- https://www.hani.co.kr
- https://www.yna.co.kr

<b>ì‡¼í•‘ëª°:</b>
- https://www.coupang.com
- https://www.gmarket.co.kr
- https://www.11st.co.kr

<b>SNS:</b>
- https://twitter.com
- https://www.instagram.com
- https://www.facebook.com
</div>
""", unsafe_allow_html=True)

col1, col2 = st.columns([2, 1])

with col1:
    url = st.text_input('URL ì…ë ¥:', placeholder='https://example.com')
    
with col2:
    parse_button = st.button('ë©”íƒ€ë°ì´í„° íŒŒì‹±', type='primary')

if url and parse_button:
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
        
    with st.spinner('ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
        result = parse_og_metadata(url)
        
    if result:
        st.markdown("<div class='output-container'>", unsafe_allow_html=True)
        
        st.subheader('ğŸ“Š ë©”íƒ€ë°ì´í„° ê²°ê³¼')
        
        meta_col1, meta_col2 = st.columns(2)
        
        with meta_col1:
            st.markdown("**ì œëª©:**")
            st.write(result['title'] if result['title'] else 'ì—†ìŒ')
            
            st.markdown("**ì„¤ëª…:**")
            st.write(result['description'] if result['description'] else 'ì—†ìŒ')
            
            st.markdown("**ì‚¬ì´íŠ¸ëª…:**")
            st.write(result['site_name'] if result['site_name'] else 'ì—†ìŒ')
            
        with meta_col2:
            st.markdown("**URL:**")
            st.write(result['url'])
            
            if result['image']:
                st.markdown("**ì´ë¯¸ì§€ URL:**")
                st.write(result['image'])
        
        if result['image']:
            st.subheader('ğŸ“· ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€')
            try:
                st.image(result['image'], use_column_width=True)
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                
        st.markdown("</div>", unsafe_allow_html=True)
        
        st.subheader('ğŸ“¤ ë‚´ë³´ë‚´ê¸° ì˜µì…˜')
        import json
        json_str = json.dumps(result, indent=2, ensure_ascii=False)
        st.download_button(
            label="JSON ë‹¤ìš´ë¡œë“œ",
            data=json_str,
            file_name="og_metadata.json",
            mime="application/json"
        )
        
    else:
        st.error('ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')

st.markdown("""
---
Streamlitìœ¼ë¡œ ì œì‘ë¨ â¤ï¸
""")
